---
title: "📃 K-폴드 교차 검증에서 K의 값을 선택할 때 고려해야 할 점은 무엇일까요?"
tags:
    - 데이터
    - 수학
    - 머신러닝
date: "2025-08-22"
thumbnail: "/assets/img/thumbnail/K-폴드.png"
---

# 📃 K-폴드 교차검증에서 K의 값을 선택할 때 고려해야 할 점은 무엇일까요?
---
안녕하십니까 오늘은 K-폴드 교차검증에서 K의 값을 선택할 때 고려해야 할 점에 대해 알아보겠습니다.
## 📚 K-폴드 교차검증의 필요성
K-폴드 교차 검증이란 K개의 fold를 만들어서 진행하는 교차검증입니다. K-폴드 교차검증을 사용하는 이유는 아래와 같습니다.
* 고정된 학습 데이터와 테스트 데이터로 평가를 하다보면 학습 데이터에만 최적의 성능을 발휘할 수 있도록 편향된 모델을 유도하는 경향이 생김
* 이 경우 모델이 학습 데이터에만 과도하게 최적화되어 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어짐
* 이러한 과적합을 피하기 위해 '교차 검증'이 필요합니다.

## 📚 K-Fold 교차검증 과정
1. 전체 데이터를 K개의 그룹으로 나눕니다.
2. 하나는 test dataset, 나머지는 train dataset으로 사용해 성능을 구합니다.
3. K개의 test dataset이 존재하게 되므로, 2번의 과정을 K번 반복합니다.
4. 매 시기마다의 성능 평균을 도출하면, 이것이 머신러닝 모델의 최종 성능 지표가 됩니다.
![K-폴드](/assets/img/교차검증.png)

## 🔍 그러면 K값을 선택할 때 고려해야 할 점은 무엇일까요?
* K값은 데이터 표본에 대해 신중하게 선택해야 합니다.
* K에 대해 잘못 선택된 값은 분산이 높은 점수(모형을 적합하는 데 사용된 데이터에 따라 많이 변경될 수 있음) 또는 높은 편향(예: 모형의 기술 과대 평가)과 같이 모형의 기술을 잘못 대표하는 아이디어를 초래할 수 있습니다.
* K값을 선택하는 세 가지 일반적인 전술은 다음과 같습니다.
    * 대표: K의 값은 데이터 샘플의 각 학습/테스트 그룹이 더 넓은 데이터 세트를 통계적으로 대표할 만큼 충분히 크도록 선택합니다.
    * K=10: K의 값은 10으로 고정되며, 이 값은 실험을 통해 발견되어 일반적으로 낮은 편향과 적당한 분산을 가진 모델 기술 추정치를 산출합니다.
    * K=n: K의 값은 n으로 고정되며, 여기서 n은 각 테스트 샘플에 홀드아웃 데이터 세트에 사용할 기회를 제공하기 위한 데이터 세트의 크기. 이 접근방식을 리브-원-아웃 교차검증이라고 합니다.
* K의 선택은 일반적으로 5 또는 10이지만 공식적인 규칙은 없습니다. K가 커질수록 훈련 세트와 리샘플링 부분 세트 간의 크기 차이가 작아집니다. 이 차이가 감소하면 기술의 편향이 작아집니다.
* K=10 값은 응용 머신러닝 분야에서 매우 일반적이며 데이터 세트의 값을 선택하는 데 어려움을 겪고 있는 경우 권장합니다.
* **데이터 샘플을 균등하게 분할하지 않는 K 값을 선택하면 한 그룹에 나머지 예제가 포함될 수 있습니다. 데이터 샘플을 동일한 수의 샘플을 갖는 K 그룹으로 분할하여 모델 기술 점수의 샘플이 모두 동일하도록 하는 것이 바람직합니다.**