---
title: "📃 LLM 핵심 개념 정리 — 할루시네이션, 모델 규모 한계, PEFT의 필요성"
tags:
    - LLM
    - 자연어
    - 모델
date: "2025-11-30"
thumbnail: "/assets/img/thumbnail/LLM.png"
---

# 📃 LLM 핵심 개념 정리 — 할루시네이션, 모델 규모 한계, PEFT의 필요성

---

## 1. LLM의 할루시네이션(Hallucination)이란 무엇이며 왜 문제가 되는가?

### 1-1. 할루시네이션의 정의
- LLM이 **사실과 다른 내용**, **근거 없는 주장**, **존재하지 않는 정보**를 마치 사실처럼 생성하는 현상.

### 1-2. 왜 발생하는가?
- 확률 기반 생성 구조  
- 훈련 데이터의 불완전성  
- 최신 정보 미반영  
- 정답 불확실 상황에서의 과잉 추론

### 1-3. 왜 문제가 되는가?
- 잘못된 정보로 인한 사용자 피해  
- 고위험 영역(의료·법률)에서 위험성 증가  
- 신뢰성 저하  
- 검증 비용 증가

### 1-4. LLM 서비스의 해결 시도
- **RAG(Search + LLM)**  
- **Fact-checking 모델 추가**  
- **도구 활용(검색·계산기 등)**  
- **RLHF/RLAIF 등 안전성 강화 데이터 학습**  
- **도메인 특화 파인튜닝**

---

## 2. 모델 크기 증가만으로는 성능이 일정 시점 이후 둔화되는 이유

### 2-1. Scaling Law의 한계
- 초기에는 모델 크기 증가 → 성능 증가  
- 이후에는 **데이터·계산 한계**로 정체

### 2-2. 데이터 부족
- 모델 크기 대비 고품질 데이터가 부족  
- 중복·노이즈 데이터로 인한 학습 비효율  
- 과적합 위험 증가

### 2-3. 계산 비용의 문제
- 대형 모델은 학습 반복이 제한됨  
- 최적화가 충분히 이뤄지지 않음

### 2-4. 구조적 한계
- Attention의 O(n²) 비용  
- 긴 문맥 처리 비용 증가

---

## 3. PEFT가 필요한 이유와 효과적 상황

### 3-1. PEFT란?
- **전체 모델이 아닌 일부 파라미터만 학습하는 파인튜닝 기법**
- 예: LoRA, Prefix Tuning, Adapter 등

### 3-2. 필요한 이유
- 초대형 모델 전체 미세조정이 비용·VRAM 면에서 비현실적  
- 더 빠른 훈련  
- 적은 데이터로도 강력한 성능  
- 원본 모델의 지식 손실 방지

### 3-3. 특히 효과적인 상황
- 소규모 데이터 기반 도메인 특화 작업  
- 제한된 GPU 환경  
- 여러 태스크를 하나의 모델 기반으로 운영할 때  
- 개인정보·기업 내부 데이터 사용 시

---

## 결론 요약
- **할루시네이션**: 사실이 아닌 내용을 생성하는 문제 → RAG, 검증 모델, 도구 활용으로 개선  
- **모델 크기 증가의 한계**: 데이터·계산·구조적 병목으로 인해 성능 증가 정체  
- **PEFT**: 초대형 모델을 경제적·효율적으로 특정 태스크에 특화하기 위한 핵심 기술



